{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Make sure you have the following packages in your environment installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install langchain==0.3.25 langchain-community==0.3.25 langchain-ollama==0.3.3 chromadb==1.0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load your documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One single document:\n",
      "\n",
      "'CLEVER HANS\n",
      "\n",
      "The mother of Hans said: ‘Whither away, Hans?’ Hans answered: ‘To Gretel.’ ‘Behave well, Hans.’ ‘Oh, I’ll behave well. Goodbye, mother.’ ‘Goodbye, Hans.’ Hans comes to Gretel. ‘Good day, Gretel.’ ‘Good day, Hans. What do you bring that is good?’ ‘I bring nothing, I want to have something given me.’ Gretel presents Hans with a needle, Hans says: ‘Goodbye, Gretel.’ ‘Goodbye, Hans.’\n",
      "\n",
      "Hans takes the needle, sticks it into a hay-cart, and follows the cart home. ‘Good evening, mother.’ ‘Good evening, Hans. Where have you been?’ ‘With Gretel.’ ‘What did you take her?’ ‘Took nothing; had something given me.’ ‘What did Gretel give you?’ ‘Gave me a needle.’ ‘Where is the needle, Hans?’ ‘Stuck in the hay-cart.’ ‘That was ill done, Hans. You should have stuck the needle in your sleeve.’ ‘Never mind, I’ll do better next time.’\n",
      "\n",
      "‘Whither away, Hans?’ ‘To Gretel, mother.’ ‘Behave well, Hans.’ ‘Oh, I’ll behave well. Goodbye, mother.’ ‘Goodbye, Hans.’ Hans comes to Gretel. ‘Good day, Gretel.’ ‘Good day, Hans. What do you bring that is good?’ ‘I bring nothing. I want to have something given to me.’ Gretel presents Hans with a knife. ‘Goodbye, Gretel.’ ‘Goodbye, Hans.’ Hans takes the knife, sticks it in his sleeve, and goes home. ‘Good evening, mother.’ ‘Good evening, Hans. Where have you been?’ ‘With Gretel.’ What did you take her?’ ‘Took her nothing, she gave me something.’ ‘What did Gretel give you?’ ‘Gave me a knife.’ ‘Where is the knife, Hans?’ ‘Stuck in my sleeve.’ ‘That’s ill done, Hans, you should have put the knife in your pocket.’ ‘Never mind, will do better next time.’\n",
      "\n",
      "‘Whither away, Hans?’ ‘To Gretel, mother.’ ‘Behave well, Hans.’ ‘Oh, I’ll behave well. Goodbye, mother.’ ‘Goodbye, Hans.’ Hans comes to Gretel. ‘Good day, Gretel.’ ‘Good day, Hans. What good thing do you bring?’ ‘I bring nothing, I want something given me.’ Gretel presents Hans with a young goat. ‘Goodbye, Gretel.’ ‘Goodbye, Hans.’ Hans takes the goat, ties its legs, and puts it in his pocket. When he gets home it is suffocated. ‘Good evening, mother.’ ‘Good evening, Hans. Where have you been?’ ‘With Gretel.’ ‘What did you take her?’ ‘Took nothing, she gave me something.’ ‘What did Gretel give you?’ ‘She gave me a goat.’ ‘Where is the goat, Hans?’ ‘Put it in my pocket.’ ‘That was ill done, Hans, you should have put a rope round the goat’s neck.’ ‘Never mind, will do better next time.’\n",
      "\n",
      "‘Whither away, Hans?’ ‘To Gretel, mother.’ ‘Behave well, Hans.’ ‘Oh, I’ll behave well. Goodbye, mother.’ ‘Goodbye, Hans.’ Hans comes to Gretel. ‘Good day, Gretel.’ ‘Good day, Hans. What good thing do you bring?’ ‘I bring nothing, I want something given me.’ Gretel presents Hans with a piece of bacon. ‘Goodbye, Gretel.’ ‘Goodbye, Hans.’\n",
      "\n",
      "Hans takes the bacon, ties it to a rope, and drags it away behind him. The dogs come and devour the bacon. When he gets home, he has the rope in his hand, and there is no longer anything hanging on to it. ‘Good evening, mother.’ ‘Good evening, Hans. Where have you been?’ ‘With Gretel.’ ‘What did you take her?’ ‘I took her nothing, she gave me something.’ ‘What did Gretel give you?’ ‘Gave me a bit of bacon.’ ‘Where is the bacon, Hans?’ ‘I tied it to a rope, brought it home, dogs took it.’ ‘That was ill done, Hans, you should have carried the bacon on your head.’ ‘Never mind, will do better next time.’\n",
      "\n",
      "‘Whither away, Hans?’ ‘To Gretel, mother.’ ‘Behave well, Hans.’ ‘I’ll behave well. Goodbye, mother.’ ‘Goodbye, Hans.’ Hans comes to Gretel. ‘Good day, Gretel.’ ‘Good day, Hans, What good thing do you bring?’ ‘I bring nothing, but would have something given.’ Gretel presents Hans with a calf. ‘Goodbye, Gretel.’ ‘Goodbye, Hans.’\n",
      "\n",
      "Hans takes the calf, puts it on his head, and the calf kicks his face. ‘Good evening, mother.’ ‘Good evening, Hans. Where have you been?’ ‘With Gretel.’ ‘What did you take her?’ ‘I took nothing, but had something given me.’ ‘What did Gretel give you?’ ‘A calf.’ ‘Where have you the calf, Hans?’ ‘I set it on my head and it kicked my face.’ ‘That was ill done, Hans, you should have led the calf, and put it in the stall.’ ‘Never mind, will do better next time.’\n",
      "\n",
      "‘Whither away, Hans?’ ‘To Gretel, mother.’ ‘Behave well, Hans.’ ‘I’ll behave well. Goodbye, mother.’ ‘Goodbye, Hans.’\n",
      "\n",
      "Hans comes to Gretel. ‘Good day, Gretel.’ ‘Good day, Hans. What good thing do you bring?’ ‘I bring nothing, but would have something given.’ Gretel says to Hans: ‘I will go with you.’\n",
      "\n",
      "Hans takes Gretel, ties her to a rope, leads her to the rack, and binds her fast. Then Hans goes to his mother. ‘Good evening, mother.’ ‘Good evening, Hans. Where have you been?’ ‘With Gretel.’ ‘What did you take her?’ ‘I took her nothing.’ ‘What did Gretel give you?’ ‘She gave me nothing, she came with me.’ ‘Where have you left Gretel?’ ‘I led her by the rope, tied her to the rack, and scattered some grass for her.’ ‘That was ill done, Hans, you should have cast friendly eyes on her.’ ‘Never mind, will do better.’\n",
      "\n",
      "Hans went into the stable, cut out all the calves’ and sheep’s eyes, and threw them in Gretel’s face. Then Gretel became angry, tore herself loose and ran away, and was no longer the bride of Hans.'\n",
      "\n",
      "From the text file:\n",
      "'documents\\clever_hans.txt'\n"
     ]
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    \"./documents\",\n",
    "    glob=\"**/*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={\"encoding\": \"utf-8\"}\n",
    ")\n",
    "docs = loader.load()\n",
    "print(f\"One single document:\\n\\n'{docs[1].page_content}'\\n\\nFrom the text file:\\n'{docs[1].metadata['source']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chunk your documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One single document chunk:\n",
      "'if the master was not coming with his guest, but she saw no one, and went back to the fowls and thought: ‘One of the wings is burning! I had better take it off and eat it.’ So she cut it off, ate it, and enjoyed it, and when she had done, she thought: ‘The other must go down too, or else master will observe that something is missing.’ When the two wings were eaten, she went and looked for her master, and did not see him. It suddenly occurred to her: ‘Who knows? They are perhaps not coming at all, and have'\n",
      "\n",
      "From the file:\n",
      "'documents\\clever_gretel.txt'\n"
     ]
    }
   ],
   "source": [
    "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=128)\n",
    "chunks = splitter.split_documents(docs)\n",
    "print(f\"One single document chunk:\\n'{chunks[5].page_content}'\\n\\nFrom the file:\\n'{chunks[5].metadata['source']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Embed and index chunks in a vector database\n",
    "Make sure to execute `ollama pull all-minilm` in the terminal before running the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama pull all-minilm\n",
    "# !ollama pull nomic-embed-text\n",
    "# !ollama pull mxbai-embed-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "model \"mxbai-embed-large\" not found, try pulling it first (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Create a vector store to store the embeddings or our chunked documents\u001b[39;00m\n\u001b[32m      6\u001b[39m embed_model = OllamaEmbeddings(model=model, base_url=\u001b[33m\"\u001b[39m\u001b[33mhttp://127.0.0.1:11434\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m vector_store = \u001b[43mChroma\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m collection = vector_store._collection\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTotal amount of chunks / embeddings:\u001b[39m\u001b[33m\"\u001b[39m, collection.count())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001b[39m, in \u001b[36mChroma.from_documents\u001b[39m\u001b[34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    885\u001b[39m texts = [doc.page_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m    886\u001b[39m metadatas = [doc.metadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[43m=\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_community\\vectorstores\\chroma.py:843\u001b[39m, in \u001b[36mChroma.from_texts\u001b[39m\u001b[34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mchromadb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[32m    837\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[32m    838\u001b[39m         api=chroma_collection._client,\n\u001b[32m    839\u001b[39m         ids=ids,\n\u001b[32m    840\u001b[39m         metadatas=metadatas,\n\u001b[32m    841\u001b[39m         documents=texts,\n\u001b[32m    842\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m         \u001b[43mchroma_collection\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    849\u001b[39m     chroma_collection.add_texts(texts=texts, metadatas=metadatas, ids=ids)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_community\\vectorstores\\chroma.py:277\u001b[39m, in \u001b[36mChroma.add_texts\u001b[39m\u001b[34m(self, texts, metadatas, ids, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m texts = \u001b[38;5;28mlist\u001b[39m(texts)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._embedding_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     embeddings = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_embedding_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadatas:\n\u001b[32m    279\u001b[39m     \u001b[38;5;66;03m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[32m    280\u001b[39m     \u001b[38;5;66;03m# did not specify metadata for all texts\u001b[39;00m\n\u001b[32m    281\u001b[39m     length_diff = \u001b[38;5;28mlen\u001b[39m(texts) - \u001b[38;5;28mlen\u001b[39m(metadatas)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_ollama\\embeddings.py:265\u001b[39m, in \u001b[36mOllamaEmbeddings.embed_documents\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[32m    264\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Embed search docs.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m     embedded_docs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_default_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeep_alive\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33membeddings\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    268\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m embedded_docs\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\ollama\\_client.py:357\u001b[39m, in \u001b[36mClient.embed\u001b[39m\u001b[34m(self, model, input, truncate, options, keep_alive)\u001b[39m\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34membed\u001b[39m(\n\u001b[32m    350\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    351\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    355\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    356\u001b[39m ) -> EmbedResponse:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEmbedResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/embed\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEmbedRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\ollama\\_client.py:178\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Program Files\\Python312\\Lib\\site-packages\\ollama\\_client.py:122\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    124\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mResponseError\u001b[39m: model \"mxbai-embed-large\" not found, try pulling it first (status code: 404)"
     ]
    }
   ],
   "source": [
    "# model = \"all-minilm\"         # 23M parameters\n",
    "# model = \"nomic-embed-text\"   # 137M parameters\n",
    "model = \"mxbai-embed-large\"   # 334M parameters\n",
    "\n",
    "# Create a vector store to store the embeddings or our chunked documents\n",
    "embed_model = OllamaEmbeddings(model=model, base_url=\"http://127.0.0.1:11434\")\n",
    "vector_store = Chroma.from_documents(chunks, embed_model)\n",
    "collection = vector_store._collection\n",
    "\n",
    "print(\"Total amount of chunks / embeddings:\", collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One single document:\n",
      "It happened that the cat met the fox in a forest, and as she thought to herself: ‘He is clever and full of experience, and much esteemed in the world,’ she spoke to him in a friendly way. ‘Good day, dear Mr Fox, how are you? How is all with you? How are you getting on in these hard times?’ The fox, full of all kinds of arrogance, looked at the cat from head to foot, and for a long time did not know whether he would give any answer or not. At last he said: ‘Oh, you wretched beard-cleaner, you piebald fool,\n",
      "\n",
      "The document's embedding:\n",
      "[ 0.04361834  0.0033501   0.01679566 ...  0.01759302  0.00692107\n",
      " -0.00018101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_data = collection.get(include=[\"documents\", \"embeddings\"])\n",
    "print(f\"One single document:\\n{all_data['documents'][1]}\\n\")\n",
    "print(f\"The document's embedding:\\n{all_data['embeddings'][1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create a Retrieval-QA chain\n",
    "Make sure to execute `ollama pull gemma3:1b` in the terminal before running the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ollama pull gemma3:1b\n",
    "# !ollama pull llama3.2\n",
    "# !ollama pull mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOllamaLLM\u001b[0m\n",
      "Params: {}\n"
     ]
    }
   ],
   "source": [
    "# model = \"gemma3:1b\"     # 1B parameters\n",
    "# model = \"llama3.2\"    # 3B parameters\n",
    "model = \"mistral\"     # 7B parameters\n",
    "\n",
    "# Create a language model with an endpoint, and a RetrievalQA chain which takes the language model,\n",
    "# and the vector store containing our documents.\n",
    "llm = OllamaLLM(\n",
    "    model=model,\n",
    "    base_url=\"http://127.0.0.1:11434\",\n",
    "    temperature=0.9,\n",
    "    top_p=0.95,\n",
    "    top_k=46,\n",
    "    # num_predict=256,\n",
    "    )\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=vector_store.as_retriever(search_kwargs={\"k\": 10}), # We set the number of chunks to return k\n",
    "    chain_type=\"stuff\",            # or \"map_reduce\", \"refine\", etc.\n",
    "    return_source_documents=True,  # if you want the source chunks back\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Ask questions!\n",
    "Some examples:\n",
    "### 6.1. \"Who is Clever Hans in the Grimm Fairy Tales?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without RAG\n",
    "query = \"Who is Clever Hans in the Grimm Fairy Tales?\"\n",
    "result = llm.invoke(query)\n",
    "print(f\"Answer: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With RAG\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(f\"Answer: {result['result']}\\n\")\n",
    "print(f\"Source: {result['source_documents']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 \"Cite what the frog says in the “The Frog Prince” in the Grimm Fairy Tales when he tries to visit the princess\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without RAG\n",
    "query = \"Cite what the frog says in the “The Frog Prince” in the Grimm Fairy Tales when he tries to visit the princess\"\n",
    "result = llm.invoke(query)\n",
    "print(f\"Answer: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With RAG\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(f\"Answer: {result['result']}\\n\")\n",
    "print(f\"Source: {result['source_documents']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 \"What is the fairy tale 'Fundevogel' about?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  \"Fundevogel\" is a German folktale, also known as \"Fledermans,\" which means \"Bat-man.\" The story revolves around a miller and his two sons. The elder son was lazy and foolish while the younger one was smart and industrious.\n",
      "\n",
      "The younger son was sent out to earn his living, and on his way, he encountered an old man who offered him a magical flute in exchange for whatever he got out of it afterward. The young man accepted, and the old man also gave him three golden seeds.\n",
      "\n",
      "Upon reaching a foreign land, the young man found himself hungry, so he planted one of the golden seeds in the ground and sang into his magical flute. A huge goose popped out, which he cooked and ate. He then replanted another seed and repeated the process.\n",
      "\n",
      "Next, he decided to use the third seed to find a wife, so he planted it and played on his flute. Out came a beautiful princess who asked him for three kisses as she woke up. The young man, not knowing it was a spell, obliged her on three consecutive days. On the third day, she transformed into a beautiful woman who became his wife.\n",
      "\n",
      "The foolish elder brother, back home, discovered the magic flute and tried to use it to earn money. But when he refused to give the golden goose to a beggar, the bird turned back into its original form: an old man who cursed him to have to go and fetch water from the well for eternity.\n",
      "\n",
      "In the end, the industrious younger brother returned home rich, with his magical wife, while the foolish elder brother was doomed to an eternal life of hardship. The tale serves as a reminder that industriousness and wisdom are valued over laziness and foolishness.\n"
     ]
    }
   ],
   "source": [
    "# Without RAG\n",
    "query = \"What is the fairy tale 'Fundevogel' about?\"\n",
    "result = llm.invoke(query)\n",
    "print(f\"Answer: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  The fairy tale 'Fundevogel' is a German folktale about a forester who rescues a child from a tree in the forest that was carried away by a bird of prey. The forester raises this child, named Fundevogel, along with his own daughter Lina. The story continues to describe how they make promises to each other to remain together, transforming into various objects such as a church and a chandelier, a rose-tree and a rose, and finally a fishpond and a duck. Eventually, the witch who had enchanted the prince in another tale is defeated by the duck (Fundevogel) and they live happily together, possibly for eternity. The story is also intertwined with another tale, 'The Frog-Prince', where the prince is transformed into a frog, but later turned back into a prince by Lina.\n",
      "\n",
      "Source: [Document(metadata={'source': 'documents/fundevogel.txt'}, page_content='The forester climbed up, brought the child down, and thought to himself: ‘You will take him home with you, and bring him up with your Lina.’ He took it home, therefore, and the two children grew up together. And the one, which he had found on a tree was called Fundevogel, because a bird had carried it away. Fundevogel and Lina loved each other so dearly that when they did not see each other they were sad.'), Document(metadata={'source': 'documents/fundevogel.txt'}, page_content='FUNDEVOGEL\\n\\nThere was once a forester who went into the forest to hunt, and as he entered it he heard a sound of screaming as if a little child were there. He followed the sound, and at last came to a high tree, and at the top of this a little child was sitting, for the mother had fallen asleep under the tree with the child, and a bird of prey had seen it in her arms, had flown down, snatched it away, and set it on the high tree.'), Document(metadata={'source': 'documents/the_frog_prince.txt'}, page_content='He told her that he had been enchanted by a spiteful fairy, who had changed him into a frog; and that he had been fated so to abide till some princess should take him out of the spring, and let him eat from her plate, and sleep upon her bed for three nights. ‘You,’ said the prince, ‘have broken his cruel charm, and now I have nothing to wish for but that you should go with me into my father’s kingdom, where I will marry you, and love you as long as you live.’'), Document(metadata={'source': 'documents/fundevogel.txt'}, page_content='in two, and have broken off the rose and brought it home with you; go, and do it at once.’ They had therefore to go out and look for the second time. The children, however, saw them coming from a distance. Then Lina said: ‘Fundevogel, never leave me, and I will never leave you.’ Fundevogel said: ‘Neither now; nor ever.’ Said Lina: ‘Then do you become a church, and I’ll be the chandelier in it.’ So when the three servants came, nothing was there but a church, with a chandelier in it. They said therefore to'), Document(metadata={'source': 'documents/fundevogel.txt'}, page_content='Then the cook sent three servants after them, who were to run and overtake the children. The children, however, were sitting outside the forest, and when they saw from afar the three servants running, Lina said to Fundevogel: ‘Never leave me, and I will never leave you.’ Fundevogel said: ‘Neither now, nor ever.’ Then said Lina: ‘Do you become a rose-tree, and I the rose upon it.’ When the three servants came to the forest, nothing was there but a rose-tree and one rose on it, but the children were nowhere.'), Document(metadata={'source': 'documents/fundevogel.txt'}, page_content='not pull the church to pieces, and bring the chandelier home with you?’ And now the old cook herself got on her legs, and went with the three servants in pursuit of the children. The children, however, saw from afar that the three servants were coming, and the cook waddling after them. Then said Lina: ‘Fundevogel, never leave me, and I will never leave you.’ Then said Fundevogel: ‘Neither now, nor ever.’ Said Lina: ‘Be a fishpond, and I will be the duck upon it.’ The cook, however, came up to them, and'), Document(metadata={'source': 'documents/the_frog_prince.txt'}, page_content='THE FROG-PRINCE'), Document(metadata={'source': 'documents/fundevogel.txt'}, page_content='‘Neither now, nor ever.’ Said Lina: ‘Be a fishpond, and I will be the duck upon it.’ The cook, however, came up to them, and when she saw the pond she lay down by it, and was about to drink it up. But the duck swam quickly to her, seized her head in its beak and drew her into the water, and there the old witch had to drown. Then the children went home together, and were heartily delighted, and if they have not died, they are living still.'), Document(metadata={'source': 'documents/fundevogel.txt'}, page_content='Early next morning the forester got up and went out hunting, and when he was gone the children were still in bed. Then Lina said to Fundevogel: ‘If you will never leave me, I too will never leave you.’ Fundevogel said: ‘Neither now, nor ever will I leave you.’ Then said Lina: ‘Then will I tell you. Last night, old Sanna carried so many buckets of water into the house that I asked her why she was doing that, and she said that if I would promise not to tell anyone, and she said that early tomorrow morning'), Document(metadata={'source': 'documents/clever_hans.txt'}, page_content='‘Whither away, Hans?’ ‘To Gretel, mother.’ ‘Behave well, Hans.’ ‘Oh, I’ll behave well. Goodbye, mother.’ ‘Goodbye, Hans.’ Hans comes to Gretel. ‘Good day, Gretel.’ ‘Good day, Hans. What good thing do you bring?’ ‘I bring nothing, I want something given me.’ Gretel presents Hans with a young goat. ‘Goodbye, Gretel.’ ‘Goodbye, Hans.’ Hans takes the goat, ties its legs, and puts it in his pocket. When he gets home it is suffocated. ‘Good evening, mother.’ ‘Good evening, Hans. Where have you been?’ ‘With')]\n"
     ]
    }
   ],
   "source": [
    "# With RAG\n",
    "result = qa_chain.invoke({\"query\": query})\n",
    "print(f\"Answer: {result['result']}\\n\")\n",
    "print(f\"Source: {result['source_documents']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
